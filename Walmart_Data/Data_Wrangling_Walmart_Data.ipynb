{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling Walmart Data Set in Pyspark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "from pyspark.sql.functions import col, lit\n",
    "from pyspark.sql.window import Window\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = spark.read.csv('features.csv', header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores = spark.read.csv('stores.csv', header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = spark.read.csv('train.csv', header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+------+\n",
      "|Store|Type|  Size|\n",
      "+-----+----+------+\n",
      "|    1|   A|151315|\n",
      "|    2|   A|202307|\n",
      "|    3|   B| 37392|\n",
      "|    4|   A|205863|\n",
      "|    5|   B| 34875|\n",
      "+-----+----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stores.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----------+----------+---------+---------+---------+---------+---------+-----------+------------+---------+\n",
      "|Store|      Date|Temperature|Fuel_Price|MarkDown1|MarkDown2|MarkDown3|MarkDown4|MarkDown5|        CPI|Unemployment|IsHoliday|\n",
      "+-----+----------+-----------+----------+---------+---------+---------+---------+---------+-----------+------------+---------+\n",
      "|    1|2010-02-05|      42.31|     2.572|       NA|       NA|       NA|       NA|       NA|211.0963582|       8.106|    FALSE|\n",
      "|    1|2010-02-12|      38.51|     2.548|       NA|       NA|       NA|       NA|       NA|211.2421698|       8.106|     TRUE|\n",
      "|    1|2010-02-19|      39.93|     2.514|       NA|       NA|       NA|       NA|       NA|211.2891429|       8.106|    FALSE|\n",
      "|    1|2010-02-26|      46.63|     2.561|       NA|       NA|       NA|       NA|       NA|211.3196429|       8.106|    FALSE|\n",
      "|    1|2010-03-05|       46.5|     2.625|       NA|       NA|       NA|       NA|       NA|211.3501429|       8.106|    FALSE|\n",
      "+-----+----------+-----------+----------+---------+---------+---------+---------+---------+-----------+------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = train.join(features, on=['Store', 'Date', 'IsHoliday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+---------+----+------------+-----------+----------+---------+---------+---------+---------+---------+-----------+------------+----+------+\n",
      "|Store|      Date|IsHoliday|Dept|Weekly_Sales|Temperature|Fuel_Price|MarkDown1|MarkDown2|MarkDown3|MarkDown4|MarkDown5|        CPI|Unemployment|Type|  Size|\n",
      "+-----+----------+---------+----+------------+-----------+----------+---------+---------+---------+---------+---------+-----------+------------+----+------+\n",
      "|    1|2010-02-05|    FALSE|   1|     24924.5|      42.31|     2.572|       NA|       NA|       NA|       NA|       NA|211.0963582|       8.106|   A|151315|\n",
      "|    1|2010-02-12|     TRUE|   1|    46039.49|      38.51|     2.548|       NA|       NA|       NA|       NA|       NA|211.2421698|       8.106|   A|151315|\n",
      "|    1|2010-02-19|    FALSE|   1|    41595.55|      39.93|     2.514|       NA|       NA|       NA|       NA|       NA|211.2891429|       8.106|   A|151315|\n",
      "|    1|2010-02-26|    FALSE|   1|    19403.54|      46.63|     2.561|       NA|       NA|       NA|       NA|       NA|211.3196429|       8.106|   A|151315|\n",
      "|    1|2010-03-05|    FALSE|   1|     21827.9|       46.5|     2.625|       NA|       NA|       NA|       NA|       NA|211.3501429|       8.106|   A|151315|\n",
      "+-----+----------+---------+----+------------+-----------+----------+---------+---------+---------+---------+---------+-----------+------------+----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = df.join(stores, on=['Store'])\n",
    "df1.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.printSchema of DataFrame[Store: string, Date: string, IsHoliday: string, Dept: string, Weekly_Sales: string, Temperature: string, Fuel_Price: string, MarkDown1: string, MarkDown2: string, MarkDown3: string, MarkDown4: string, MarkDown5: string, CPI: string, Unemployment: string, Type: string, Size: string]>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cast columns as proper data types\n",
    "df2 = df1.withColumn('Store', F.col('Store').cast(T.IntegerType()))\\\n",
    "    .withColumn('Date', F.col('Date').cast(T.DateType()))\\\n",
    "    .withColumn('Dept', F.col('Dept').cast(T.IntegerType()))\\\n",
    "    .withColumn('Weekly_Sales', F.col('Weekly_Sales').cast(T.DoubleType()))\\\n",
    "    .withColumn('Temperature', F.col('Temperature').cast(T.DoubleType()))\\\n",
    "    .withColumn('Fuel_Price', F.col('Fuel_Price').cast(T.DoubleType()))\\\n",
    "    .withColumn('MarkDown1', F.col('MarkDown1').cast(T.DoubleType()))\\\n",
    "    .withColumn('MarkDown2', F.col('MarkDown2').cast(T.DoubleType()))\\\n",
    "    .withColumn('MarkDown3', F.col('MarkDown3').cast(T.DoubleType()))\\\n",
    "    .withColumn('MarkDown4', F.col('MarkDown4').cast(T.DoubleType()))\\\n",
    "    .withColumn('MarkDown5', F.col('MarkDown5').cast(T.DoubleType()))\\\n",
    "    .withColumn('CPI', F.col('CPI').cast(T.DoubleType()))\\\n",
    "    .withColumn('Unemployment', F.col('Unemployment').cast(T.DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.printSchema of DataFrame[Store: int, Date: date, IsHoliday: string, Dept: int, Weekly_Sales: double, Temperature: double, Fuel_Price: double, MarkDown1: double, MarkDown2: double, MarkDown3: double, MarkDown4: double, MarkDown5: double, CPI: double, Unemployment: double, Type: string, Size: string]>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+---------+----+------------+-----------+----------+---------+---------+---------+---------+---------+-----------+------------+----+------+\n",
      "|Store|      Date|IsHoliday|Dept|Weekly_Sales|Temperature|Fuel_Price|MarkDown1|MarkDown2|MarkDown3|MarkDown4|MarkDown5|        CPI|Unemployment|Type|  Size|\n",
      "+-----+----------+---------+----+------------+-----------+----------+---------+---------+---------+---------+---------+-----------+------------+----+------+\n",
      "|    1|2010-02-05|    FALSE|   1|     24924.5|      42.31|     2.572|     null|     null|     null|     null|     null|211.0963582|       8.106|   A|151315|\n",
      "|    1|2010-02-12|     TRUE|   1|    46039.49|      38.51|     2.548|     null|     null|     null|     null|     null|211.2421698|       8.106|   A|151315|\n",
      "|    1|2010-02-19|    FALSE|   1|    41595.55|      39.93|     2.514|     null|     null|     null|     null|     null|211.2891429|       8.106|   A|151315|\n",
      "|    1|2010-02-26|    FALSE|   1|    19403.54|      46.63|     2.561|     null|     null|     null|     null|     null|211.3196429|       8.106|   A|151315|\n",
      "|    1|2010-03-05|    FALSE|   1|     21827.9|       46.5|     2.625|     null|     null|     null|     null|     null|211.3501429|       8.106|   A|151315|\n",
      "+-----+----------+---------+----+------------+-----------+----------+---------+---------+---------+---------+---------+-----------+------------+----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+---------+----+------------+-----------+----------+---------+---------+---------+---------+---------+-----------+------------+----+------+\n",
      "|Store|      Date|IsHoliday|Dept|Weekly_Sales|Temperature|Fuel_Price|MarkDown1|MarkDown2|MarkDown3|MarkDown4|MarkDown5|        CPI|Unemployment|Type|  Size|\n",
      "+-----+----------+---------+----+------------+-----------+----------+---------+---------+---------+---------+---------+-----------+------------+----+------+\n",
      "|    1|2010-02-05|    FALSE|   1|     24924.5|      42.31|     2.572|      0.0|      0.0|      0.0|      0.0|      0.0|211.0963582|       8.106|   A|151315|\n",
      "|    1|2010-02-12|     TRUE|   1|    46039.49|      38.51|     2.548|      0.0|      0.0|      0.0|      0.0|      0.0|211.2421698|       8.106|   A|151315|\n",
      "|    1|2010-02-19|    FALSE|   1|    41595.55|      39.93|     2.514|      0.0|      0.0|      0.0|      0.0|      0.0|211.2891429|       8.106|   A|151315|\n",
      "|    1|2010-02-26|    FALSE|   1|    19403.54|      46.63|     2.561|      0.0|      0.0|      0.0|      0.0|      0.0|211.3196429|       8.106|   A|151315|\n",
      "|    1|2010-03-05|    FALSE|   1|     21827.9|       46.5|     2.625|      0.0|      0.0|      0.0|      0.0|      0.0|211.3501429|       8.106|   A|151315|\n",
      "+-----+----------+---------+----+------------+-----------+----------+---------+---------+---------+---------+---------+-----------+------------+----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### replace null values with 0\n",
    "df5 = df2.fillna(0, subset= ['MarkDown1','MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5'])\n",
    "   \n",
    "df5.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|         MarkDown4|\n",
      "+-------+------------------+\n",
      "|  count|            421570|\n",
      "|   mean|1083.1322675238291|\n",
      "| stddev| 3894.529945443478|\n",
      "|    min|               0.0|\n",
      "|    max|          67474.85|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5.describe('MarkDown4').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.coalesce(1).write.format('com.databricks.spark.csv').save('Joined_data.csv',header = 'true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
